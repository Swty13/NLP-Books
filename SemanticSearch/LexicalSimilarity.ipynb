{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Similarity\n",
    "\n",
    "When referring to lexical text similarity, people actually refer to how similar two pieces of text are at the surface level. For example, how similar are the phrases “the cat ate the mouse” with “the mouse ate the cat food” by just looking at the words? It typically does not take into account the actual meaning behind words or the entire phrase in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries\n",
    "import Levenshtein as lev\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def clean_text(doc):\n",
    "    clean_text=doc.lower()\n",
    "    clean_text = re.sub(\"-\", \" \", clean_text)\n",
    "    clean_text=clean_text.split(\" \")\n",
    "    clean_text=[lemmatizer.lemmatize(x) for x in clean_text]\n",
    "    clean_text=\" \".join(clean_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Jaccard Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DEFINITION:\n",
    "J(A,B)= Intersection of A and B/ Union of A and B\n",
    "\n",
    "J\t=\tJaccard distance\n",
    "A\t=\tset 1\n",
    "B\t=\tset 2\n",
    "\n",
    "    USE CASE:\n",
    "Jaccard Similarity algorithm is to show the the common between two text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard_Similarity(doc1, doc2): \n",
    "    \n",
    "    # List the unique words in a document\n",
    "    words_doc1 = set(doc1.split(\" \")) \n",
    "    words_doc2 = set(doc2.split(\" \"))\n",
    "    \n",
    "    # Find the intersection of words list of doc1 & doc2\n",
    "    intersection = words_doc1.intersection(words_doc2)\n",
    "\n",
    "    # Find the union of words list of doc1 & doc2\n",
    "    union = words_doc1.union(words_doc2)\n",
    "        \n",
    "    # Calculate Jaccard similarity score \n",
    "    # using length of intersection set divided by length of union set\n",
    "    jac_similarity = float(len(intersection)) / len(union)\n",
    "    return (jac_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jaccard_Similarity(\"Communication skill\",\"Communication\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Levenshtein Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levenshtein Distance called as Minimum Edit distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lev_Similarity(doc1, doc2):     \n",
    "    words_doc1 = clean_text(doc1)\n",
    "    words_doc2 = clean_text(doc2)\n",
    "    Distance = lev.distance(words_doc1, words_doc2)\n",
    "    Ratio = lev.ratio(words_doc1,words_doc2)       \n",
    "    return (Distance,Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.9090909090909091)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lev_Similarity(\"Color\",\"Colour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Score calculation behind Levenshtein Distance and Levenshtein Ratio:\n",
    "Calculation of Levenshtein Distance: \n",
    "\n",
    "It is calculated by counting number of edits required to transform one string into another. The edits could be one of the following:\n",
    " 1. Addition of a new letter\n",
    " 2. Removal of a letter\n",
    " 3. Replacement of a letter\n",
    " \n",
    " \n",
    "Calculation of Levenshtein Ratio: \n",
    "\n",
    "1. Replacement of any word will cost 2 points (4-2)/2 = 0.5\n",
    "2. Deletion of any word will cost 1 point     (3-1)/3 =0.666\n",
    "3. Insertion of any word will cost 1 point    (5-1)/5 = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Replacement\n",
    "Lev_Similarity(\"ab\",\"ad\")        ### change of 1 word i.e d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Deletion\n",
    "Lev_Similarity(\"ab\",\"a\")        ### change of 1 word i.e b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Insertion\n",
    "Lev_Similarity(\"ab\",\"abc\")      ### change of 1 word i.e c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where can lexical similarity be used?\n",
    "1. Clustering – If you want to group similar texts together how can you tell if two groups of text are even similar?\n",
    "2. Redundancy removal – If two pieces of texts are so similar, why do we need both? You can always eliminate the redundant one. Think of duplicate product listings, or the same person in your database, with slight variation in the name or even html pages that are near duplicates.\n",
    "3. Information Retrieval – How do you rank documents that are similar to a query? You could start with something as simple as cosine similarity. While there are more established document retrieval measures like BM25, Language Models and PL2, you could also use a measure like cosine once you have a vector representation of your query and documents. You can even use Jaccard for information retrieval tasks, but this is not very effective as term frequencies are completely ignored by Jaccard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fuzzy Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ratio: This function used to calculate the Levenshtein distance similarity ratio between the two strings (sequences). \n",
    "2. Partial_Ratio: This function used to perform substring matching. This works by taking the shortest string and matching it with all substrings that are of the same length.\n",
    ">USE CASE:This function is also useful when matching names. For example, if one sequence was someone’s first and middle name, and the sequence you’re trying to match on is that person’s first, middle, and last name.\n",
    "3. Token_Sort_Ratio: This function can come in handy when the strings you are comparing are the same in spelling but are not in the same order. \n",
    ">USE CASE:This function is also useful when matching names are in Jumbled form. For example, \n",
    "Name1 = 'Gunner William Kline' \n",
    "Name2 = 'Kline, Gunner William'\n",
    "4. Token_Set_Ratio: This function is the most helpful when applied to a set of strings with a significant difference in lengths.\n",
    ">USE CASE:For example, \n",
    "Str1='The 3000 meter steeplechase winner, Soufiane El Bakkali' \n",
    "Str2='Soufiane El Bakkali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 58\n",
      "Partial_Ratio 100\n",
      "Token_Sort_Ratio 61\n",
      "Token_Set_Ratio 100\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "Str1 = 'Chicago, Illinois' \n",
    "Str2 = 'Chicago'\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "Token_Set_Ratio = fuzz.token_set_ratio(Str1,Str2)\n",
    "print(\"Ratio\",Ratio)\n",
    "print(\"Partial_Ratio\",Partial_Ratio)\n",
    "print(\"Token_Sort_Ratio\",Token_Sort_Ratio)\n",
    "print(\"Token_Set_Ratio\",Token_Set_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "\n",
    "1. In Jaccard Similarity, the number of common attributes is divided by the number of attributes that exists in at least one of the two objects.\n",
    "2. In Levenshtein Similarity, the number of common attributes is divided by the number of attributes that exists in at least one of the two objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
