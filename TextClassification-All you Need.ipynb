{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextClassification-All you Need\n",
    "\n",
    "\n",
    "This Notebook covers:\n",
    ">1. tfidf\n",
    ">2. count features\n",
    ">3. logistic regression\n",
    ">4. naive bayes\n",
    ">5. xgboost\n",
    ">6. grid search\n",
    ">7. word vectors(Glove)\n",
    ">8. LSTM\n",
    ">9. GRU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset contains text from works of fiction written by spooky authors of the public domain: Edgar Allan Poe, HP Lovecraft and Mary Shelley. The data was prepared by chunking larger texts into sentences using CoreNLP's MaxEnt sentence tokenizer, so you may notice the odd non-sentence here and there. Our objective is to accurately identify the author of the sentences in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU,Dense, Activation, Dropout,Embedding,BatchNormalization,SpatialDropout1D,Bidirectional\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from tensorflow.keras.preprocessing import sequence, text\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"train_multi.csv\")\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    7900\n",
       "MWS    6044\n",
       "HPL    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check target column distribution\n",
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/1/anaconda3/envs/jupyter_venv/lib/python3.6/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='author', ylabel='count'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(5,5)})\n",
    "sns.countplot(df['author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def sanitize_text(document):\n",
    "    if document == None:\n",
    "        document = \"\"\n",
    "\n",
    "    review_text = re.sub(\"[^a-zA-Z]\", \" \", document)\n",
    "    review_text = re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ', review_text)\n",
    "    review_text = review_text.lower()\n",
    "    review_text_list = review_text.split(\" \")\n",
    "    review_text_list = [x.strip() for x in review_text_list]\n",
    "    review_text = \" \".join(review_text_list)\n",
    "\n",
    "    document = re.sub(' +', ' ', review_text).strip()\n",
    "    return document\n",
    "df['clean_text']=df['text'].apply(lambda x:sanitize_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function for Multi class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    v = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target data Encoding\n",
    "\n",
    "We use the LabelEncoder from scikit-learn to convert text labels to integers, 0, 1 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(df.author.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going further it is important that we split the data into training and validation sets. We can do it using train_test_split from the model_selection module of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(df.clean_text.values, \n",
    "                                                      y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17621,), (1958,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression with TF/IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always start with these features. They work (almost) everytime!\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(X_train) + list(X_valid))\n",
    "xtrain_tfv =  tfv.transform(X_train) \n",
    "xvalid_tfv = tfv.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.572 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/1/anaconda3/envs/jupyter_venv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Logistic Regression on TFIDF\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_tfv, y_train)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Loss for LR model with TFIDF 0.572"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "\n",
    "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n",
    "ctv.fit(list(X_train) + list(X_valid))\n",
    "xtrain_ctv =  ctv.transform(X_train) \n",
    "xvalid_ctv = ctv.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.526 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/1/anaconda3/envs/jupyter_venv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Logistic Regression on Counts\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_ctv, y_train)\n",
    "predictions = clf.predict_proba(xvalid_ctv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Loss for LR model with CountVectorizer 0.526"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MultinomialNB with TF/IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.577 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on Counts\n",
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain_tfv, y_train)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Loss for Naive Bayes model with TFIDF 0.577"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  MultinomialNB with Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.485 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on Counts\n",
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain_ctv, y_train)\n",
    "predictions = clf.predict_proba(xvalid_ctv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Loss for Naive Bayes model with Count Vectorizer 0.485"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. XGBOOST with TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:17:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logloss: 0.781 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_tfv.tocsc(), y_train)\n",
    "predictions = clf.predict_proba(xvalid_tfv.tocsc())\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Loss for XGBOOST model with TFIDF 0.781"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors\n",
    "the GloVe vectors. You can download the GloVe vectors from here http://www-nlp.stanford.edu/data/glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !wget 'http://www-nlp.stanford.edu/data/glove.840B.300d.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_glove_line(line, dim):\n",
    "    word = None\n",
    "    embedding = None\n",
    "\n",
    "    try:\n",
    "        splitLine = line.split()\n",
    "        word = \" \".join(splitLine[:len(splitLine)-dim])\n",
    "        embedding = np.array([float(val) for val in splitLine[-dim:]])\n",
    "    except:\n",
    "        print(line)\n",
    "\n",
    "    return word, embedding\n",
    "\n",
    "def load_glove_model(glove_filepath, dim):\n",
    "    with open(glove_filepath, encoding=\"utf8\" ) as f:\n",
    "        content = f.readlines()\n",
    "        model = {}\n",
    "        for line in content:\n",
    "            word, embedding = process_glove_line(line, dim)\n",
    "            if embedding is not None:\n",
    "                model[word] = embedding\n",
    "        return model\n",
    "\n",
    "embeddings_index= load_glove_model(\"glove.840B.300d.txt\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2195895 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Return Normalize vector of sentence\n",
    "def sent2vec(s):\n",
    "    \n",
    "    words = word_tokenize(s)\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/17621 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 179/17621 [00:00<00:09, 1784.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 428/17621 [00:00<00:08, 1945.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 676/17621 [00:00<00:08, 2078.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|▌         | 907/17621 [00:00<00:07, 2142.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|▋         | 1161/17621 [00:00<00:07, 2246.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 1399/17621 [00:00<00:07, 2284.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|▉         | 1648/17621 [00:00<00:06, 2342.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|█         | 1905/17621 [00:00<00:06, 2404.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|█▏        | 2152/17621 [00:00<00:06, 2422.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|█▎        | 2389/17621 [00:01<00:06, 2386.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█▍        | 2637/17621 [00:01<00:06, 2407.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|█▋        | 2876/17621 [00:01<00:06, 2283.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|█▊        | 3108/17621 [00:01<00:06, 2291.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|█▉        | 3354/17621 [00:01<00:06, 2339.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|██        | 3588/17621 [00:01<00:06, 2324.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|██▏       | 3821/17621 [00:01<00:06, 2289.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|██▎       | 4051/17621 [00:01<00:05, 2291.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|██▍       | 4300/17621 [00:01<00:05, 2346.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██▌       | 4544/17621 [00:01<00:05, 2372.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██▋       | 4782/17621 [00:02<00:05, 2310.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██▊       | 5014/17621 [00:02<00:05, 2137.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|██▉       | 5251/17621 [00:02<00:05, 2201.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███       | 5491/17621 [00:02<00:05, 2257.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|███▏      | 5724/17621 [00:02<00:05, 2274.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|███▍      | 5953/17621 [00:02<00:05, 2245.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|███▌      | 6179/17621 [00:02<00:05, 2231.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|███▋      | 6415/17621 [00:02<00:04, 2267.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|███▊      | 6665/17621 [00:02<00:04, 2331.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|███▉      | 6911/17621 [00:02<00:04, 2366.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|████      | 7162/17621 [00:03<00:04, 2407.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████▏     | 7404/17621 [00:03<00:04, 2354.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████▎     | 7644/17621 [00:03<00:04, 2365.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|████▍     | 7889/17621 [00:03<00:04, 2388.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|████▌     | 8142/17621 [00:03<00:03, 2427.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|████▊     | 8393/17621 [00:03<00:03, 2448.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|████▉     | 8639/17621 [00:03<00:03, 2431.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 8883/17621 [00:03<00:03, 2430.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|█████▏    | 9127/17621 [00:03<00:03, 2358.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|█████▎    | 9364/17621 [00:04<00:03, 2330.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████▍    | 9616/17621 [00:04<00:03, 2381.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████▌    | 9874/17621 [00:04<00:03, 2436.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████▋    | 10119/17621 [00:04<00:03, 2400.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|█████▉    | 10361/17621 [00:04<00:03, 2404.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████    | 10602/17621 [00:04<00:02, 2391.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|██████▏   | 10842/17621 [00:04<00:02, 2382.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|██████▎   | 11081/17621 [00:04<00:02, 2355.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|██████▍   | 11317/17621 [00:04<00:02, 2341.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|██████▌   | 11574/17621 [00:04<00:02, 2398.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 11823/17621 [00:05<00:02, 2421.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|██████▊   | 12070/17621 [00:05<00:02, 2433.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|██████▉   | 12314/17621 [00:05<00:02, 2387.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████▏  | 12558/17621 [00:05<00:02, 2402.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|███████▎  | 12803/17621 [00:05<00:01, 2415.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|███████▍  | 13062/17621 [00:05<00:01, 2462.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|███████▌  | 13309/17621 [00:05<00:01, 2342.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|███████▋  | 13551/17621 [00:05<00:01, 2362.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|███████▊  | 13789/17621 [00:05<00:01, 2284.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|███████▉  | 14034/17621 [00:05<00:01, 2330.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|████████  | 14271/17621 [00:06<00:01, 2340.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|████████▏ | 14513/17621 [00:06<00:01, 2363.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████▍ | 14771/17621 [00:06<00:01, 2423.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████▌ | 15015/17621 [00:06<00:01, 2423.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|████████▋ | 15266/17621 [00:06<00:00, 2449.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|████████▊ | 15512/17621 [00:06<00:00, 2438.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|████████▉ | 15757/17621 [00:06<00:00, 2349.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|█████████ | 15993/17621 [00:06<00:00, 2083.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 92%|█████████▏| 16226/17621 [00:06<00:00, 2151.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 93%|█████████▎| 16471/17621 [00:07<00:00, 2231.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|█████████▍| 16708/17621 [00:07<00:00, 2269.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 96%|█████████▌| 16946/17621 [00:07<00:00, 2299.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 97%|█████████▋| 17180/17621 [00:07<00:00, 2309.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 17621/17621 [00:07<00:00, 2350.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1958 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|█         | 213/1958 [00:00<00:00, 2127.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|██▎       | 444/1958 [00:00<00:00, 2178.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|███▎      | 641/1958 [00:00<00:00, 2109.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|████▎     | 854/1958 [00:00<00:00, 2113.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████▍    | 1064/1958 [00:00<00:00, 2109.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|██████▋   | 1301/1958 [00:00<00:00, 2178.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|███████▊  | 1529/1958 [00:00<00:00, 2070.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 1958/1958 [00:00<00:00, 2179.89it/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# create sentence vectors using the above function for training and validation set\n",
    "xtrain_glove = np.array([sent2vec(x) for x in tqdm(X_train)])\n",
    "xvalid_glove = np.array([sent2vec(x) for x in tqdm(X_valid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:41:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logloss: 0.655 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on glove features\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_glove, y_train)\n",
    "predictions = clf.predict_proba(xvalid_glove)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Loss for XGBOOST with Glove embeddings 0.655"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning\n",
    "Here, we will train a simple dense network on the GloVe features. Let's start with the dense network first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data before any neural net:\n",
    "scl = preprocessing.StandardScaler()\n",
    "xtrain_glove_scl = scl.fit_transform(xtrain_glove)\n",
    "xvalid_glove_scl = scl.transform(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to binarize the labels for the neural net\n",
    "ytrain_enc = to_categorical(y_train)\n",
    "yvalid_enc = to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple 3 layer sequential neural net\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(300, input_dim=300, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17621 [05:24<?, ?it/s]\n",
      "  0%|          | 0/17621 [05:13<?, ?it/s]\n",
      "  0%|          | 0/17621 [04:46<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276/276 [==============================] - 3s 5ms/step - loss: 0.8937 - val_loss: 0.6803\n",
      "Epoch 2/5\n",
      "276/276 [==============================] - 1s 5ms/step - loss: 0.6744 - val_loss: 0.6447\n",
      "Epoch 3/5\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.6072 - val_loss: 0.6421\n",
      "Epoch 4/5\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.5635 - val_loss: 0.6381\n",
      "Epoch 5/5\n",
      "276/276 [==============================] - 1s 4ms/step - loss: 0.5365 - val_loss: 0.6260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f70704ba0b8>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_glove_scl, y=ytrain_enc, batch_size=64, \n",
    "          epochs=5, verbose=1, \n",
    "          validation_data=(xvalid_glove_scl, yvalid_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Loss of Simple DNN 0.62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras tokenizer here\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 70\n",
    "\n",
    "token.fit_on_texts(list(X_train) + list(X_valid))\n",
    "xtrain_seq = token.texts_to_sequences(X_train)\n",
    "xvalid_seq = token.texts_to_sequences(X_valid)\n",
    "\n",
    "# zero pad the sequences\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25076/25076 [00:00<00:00, 254826.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# create an embedding matrix for the words we have in the dataset\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple LSTM with glove embeddings and two dense layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 18s 423ms/step - loss: 1.0584 - val_loss: 0.9290\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 15s 442ms/step - loss: 0.9111 - val_loss: 0.7562\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.8222 - val_loss: 0.7239\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.7855 - val_loss: 0.6870\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 15s 428ms/step - loss: 0.7651 - val_loss: 0.7076\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 15s 437ms/step - loss: 0.7522 - val_loss: 0.6584\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.7247 - val_loss: 0.6388\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 15s 428ms/step - loss: 0.7025 - val_loss: 0.6257\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 15s 424ms/step - loss: 0.6903 - val_loss: 0.6261\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 15s 439ms/step - loss: 0.6769 - val_loss: 0.5933\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.6516 - val_loss: 0.5974\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.6298 - val_loss: 0.5782\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.6118 - val_loss: 0.5808\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 15s 439ms/step - loss: 0.5991 - val_loss: 0.5694\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 15s 426ms/step - loss: 0.5760 - val_loss: 0.5449\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.5554 - val_loss: 0.5459\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.5508 - val_loss: 0.5351\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 15s 431ms/step - loss: 0.5336 - val_loss: 0.5323\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.5162 - val_loss: 0.5484\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 15s 439ms/step - loss: 0.5018 - val_loss: 0.5323\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.4957 - val_loss: 0.5334\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.4874 - val_loss: 0.5350\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.4753 - val_loss: 0.5193\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.4636 - val_loss: 0.5497\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.4586 - val_loss: 0.5178\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.4546 - val_loss: 0.5102\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 15s 425ms/step - loss: 0.4334 - val_loss: 0.5077\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 15s 425ms/step - loss: 0.4446 - val_loss: 0.5084\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.4212 - val_loss: 0.5119\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.4090 - val_loss: 0.5082\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 15s 424ms/step - loss: 0.4060 - val_loss: 0.5146\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 15s 440ms/step - loss: 0.4047 - val_loss: 0.5051\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.3941 - val_loss: 0.5474\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.3920 - val_loss: 0.5092\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.3897 - val_loss: 0.5056\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 15s 428ms/step - loss: 0.3758 - val_loss: 0.5170\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 15s 424ms/step - loss: 0.3671 - val_loss: 0.5215\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 15s 426ms/step - loss: 0.3684 - val_loss: 0.5207\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.3533 - val_loss: 0.5083\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.3504 - val_loss: 0.5050\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 15s 427ms/step - loss: 0.3475 - val_loss: 0.4993\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.3415 - val_loss: 0.5109\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.3365 - val_loss: 0.5446\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.3452 - val_loss: 0.5486\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.3385 - val_loss: 0.5054\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 16s 444ms/step - loss: 0.3258 - val_loss: 0.5342\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.3249 - val_loss: 0.5254\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 15s 428ms/step - loss: 0.3202 - val_loss: 0.5099\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.3079 - val_loss: 0.5256\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.3093 - val_loss: 0.5429\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 15s 421ms/step - loss: 0.3079 - val_loss: 0.5227\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 15s 431ms/step - loss: 0.2977 - val_loss: 0.5277\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.3026 - val_loss: 0.5252\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.2899 - val_loss: 0.5359\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 15s 437ms/step - loss: 0.2848 - val_loss: 0.5183\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 15s 427ms/step - loss: 0.2912 - val_loss: 0.5165\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.2866 - val_loss: 0.5372\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 15s 431ms/step - loss: 0.2882 - val_loss: 0.5291\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.2847 - val_loss: 0.5556\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.2847 - val_loss: 0.5172\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.2741 - val_loss: 0.5286\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 15s 425ms/step - loss: 0.2728 - val_loss: 0.5211\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.2689 - val_loss: 0.5422\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.2665 - val_loss: 0.5452\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 15s 426ms/step - loss: 0.2628 - val_loss: 0.5240\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.2641 - val_loss: 0.5492\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.2658 - val_loss: 0.5370\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 15s 431ms/step - loss: 0.2527 - val_loss: 0.5487\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.2546 - val_loss: 0.5371\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.2475 - val_loss: 0.5525\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.2542 - val_loss: 0.5456\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.2489 - val_loss: 0.5330\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.2455 - val_loss: 0.5453\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 15s 428ms/step - loss: 0.2386 - val_loss: 0.5507\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 15s 424ms/step - loss: 0.2422 - val_loss: 0.5521\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.2382 - val_loss: 0.5585\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 15s 427ms/step - loss: 0.2344 - val_loss: 0.5649\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 15s 425ms/step - loss: 0.2343 - val_loss: 0.5702\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.2299 - val_loss: 0.5491\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 15s 431ms/step - loss: 0.2329 - val_loss: 0.5620\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 15s 443ms/step - loss: 0.2256 - val_loss: 0.5877\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 15s 424ms/step - loss: 0.2366 - val_loss: 0.5593\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 15s 426ms/step - loss: 0.2229 - val_loss: 0.5834\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 15s 424ms/step - loss: 0.2188 - val_loss: 0.5792\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.2163 - val_loss: 0.6367\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 15s 421ms/step - loss: 0.2285 - val_loss: 0.5745\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 15s 439ms/step - loss: 0.2198 - val_loss: 0.5783\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.2178 - val_loss: 0.5318\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 15s 431ms/step - loss: 0.2198 - val_loss: 0.5581\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.2148 - val_loss: 0.5680\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 15s 425ms/step - loss: 0.2165 - val_loss: 0.5346\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.2170 - val_loss: 0.5463\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.2138 - val_loss: 0.5947\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.2008 - val_loss: 0.5735\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.2054 - val_loss: 0.5926\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.1996 - val_loss: 0.5647\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 15s 428ms/step - loss: 0.1949 - val_loss: 0.5878\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.1966 - val_loss: 0.5709\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.1995 - val_loss: 0.5548\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.1996 - val_loss: 0.5962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7034b2e518>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, verbose=1, validation_data=(xvalid_pad, yvalid_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Loss of LSTM 0.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BI-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 42s 1s/step - loss: 1.0390 - val_loss: 0.8663\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.8562 - val_loss: 0.7310\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.7978 - val_loss: 0.7051\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.7730 - val_loss: 0.6885\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.7583 - val_loss: 0.6859\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.7330 - val_loss: 0.6708\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.7093 - val_loss: 0.6334\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.6778 - val_loss: 0.6395\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.6652 - val_loss: 0.6445\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.6276 - val_loss: 0.5824\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.6043 - val_loss: 0.6079\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.5871 - val_loss: 0.5673\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.5769 - val_loss: 0.5551\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.5477 - val_loss: 0.5409\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.5117 - val_loss: 0.5452\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.4990 - val_loss: 0.5337\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.4996 - val_loss: 0.5659\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.4846 - val_loss: 0.5349\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.4564 - val_loss: 0.5290\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.4450 - val_loss: 0.5218\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.4223 - val_loss: 0.5179\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.4043 - val_loss: 0.5241\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.3826 - val_loss: 0.5281\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.3822 - val_loss: 0.5947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7035bd7e10>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple bidirectional LSTM with glove embeddings and two dense layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(300, dropout=0.3, recurrent_dropout=0.3)))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Loss of Bi-LSTM 0.594"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 69s 2s/step - loss: 1.0529 - val_loss: 0.8921\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 62s 2s/step - loss: 0.9074 - val_loss: 0.8009\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 61s 2s/step - loss: 0.8310 - val_loss: 0.7331\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 61s 2s/step - loss: 0.7911 - val_loss: 0.7018\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 61s 2s/step - loss: 0.7601 - val_loss: 0.6667\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 61s 2s/step - loss: 0.7361 - val_loss: 0.6683\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.7131 - val_loss: 0.6478\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 61s 2s/step - loss: 0.6855 - val_loss: 0.6154\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 61s 2s/step - loss: 0.6572 - val_loss: 0.5897\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.6346 - val_loss: 0.5964\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.6187 - val_loss: 0.5819\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.6113 - val_loss: 0.5886\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.5795 - val_loss: 0.5691\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.5556 - val_loss: 0.5310\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.5440 - val_loss: 0.5640\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 61s 2s/step - loss: 0.5259 - val_loss: 0.5290\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.5166 - val_loss: 0.5162\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.4911 - val_loss: 0.5410\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 61s 2s/step - loss: 0.4747 - val_loss: 0.5070\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.4687 - val_loss: 0.5080\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.4558 - val_loss: 0.4907\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.4580 - val_loss: 0.4932\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.4293 - val_loss: 0.4941\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.4209 - val_loss: 0.4913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f70342f3518>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU with glove embeddings and two dense layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Loss of GRU  0.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Text Classification on GLUE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
