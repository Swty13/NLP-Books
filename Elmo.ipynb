{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMO( Embeddings from Language Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elmo is used for building char-level embedding unlike Glove/Word2vec/BOW which used for word embeddings.\n",
    "Computes contextualized word representations using character-based word representations and bidirectional LSTMs, as described in the paper \"Deep contextualized word representations\"\n",
    "1. Captures contextual meaning of word ,having diffrent embedding for different words\n",
    "2. Handle out of Vocabulary words \n",
    "3. Capture Morphological words embeddings\n",
    "\n",
    "Instead of using a fixed embedding for each word, ELMo looks at the entire sentence before assigning each word in it an embedding. It uses a bi-directional LSTM trained on a specific task to be able to create those embeddings. ELMo provided a significant step towards pre-training in the context of NLP.\n",
    "\n",
    "1. For In depth knowledge of ELMO Architecture refer :https://www.mihaileric.com/posts/deep-contextualized-word-representations-elmo/\n",
    "2. Elmo Architecture papaer refer : https://arxiv.org/pdf/1508.06615.pdf\n",
    "3. For Highway Netwrk refer : https://towardsdatascience.com/review-highway-networks-gating-function-to-highway-image-classification-5a33833797b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elmo Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "elmo =hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False) ### Load Elmo Model\n",
    "\n",
    "text1=\"She sat on the river bank across from a series of wide, large steps leading up a hill to the park where the Arch stood, framed against a black sky.\"\n",
    "text2=\"How could a man with four million in the bank be in financial danger?\"\n",
    "\n",
    "embeddings = elmo(\n",
    "[text1, text22],\n",
    "signature=\"default\",\n",
    "as_dict=True)[\"elmo\"]\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    embeddings = session.run(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = elmo(\n",
    "[text1, text2],\n",
    "signature=\"default\",\n",
    "as_dict=True)[\"word_emb\"]\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    word_embeddings = session.run(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 27, 512)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Layer1 Embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "lstm1_embeddings = elmo(\n",
    "[text1, text2],\n",
    "signature=\"default\",\n",
    "as_dict=True)[\"lstm_outputs1\"]\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    lstm1_embeddings = session.run(lstm1_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 27, 1024)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm1_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inputs\n",
    "\n",
    "The module defines two signatures: default, and tokens.\n",
    "\n",
    "With the default signature, the module takes untokenized sentences as input. The input tensor is a string tensor with shape [batch_size]. The module tokenizes each string by splitting on spaces.\n",
    "\n",
    "With the tokens signature, the module takes tokenized sentences as input. The input tensor is a string tensor with shape [batch_size, max_length] and an int32 tensor with shape [batch_size] corresponding to the sentence length. The length input is necessary to exclude padding in the case of sentences with varying length.\n",
    "\n",
    "\n",
    "#### The output dictionary contains:\n",
    "\n",
    " 1. word_emb: the character-based word representations with shape [batch_size, max_length, 512].\n",
    " 2. lstm_outputs1: the first LSTM hidden state with shape [batch_size, max_length, 1024].\n",
    " 3. lstm_outputs2: the second LSTM hidden state with shape [batch_size, max_length, 1024].\n",
    " 4. elmo: the weighted sum of the 3 layers, where the weights are trainable. This tensor has shape [batch_size, max_length, 1024]\n",
    " 5. default: a fixed mean-pooling of all contextualized word representations with shape [batch_size, 1024]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 30, 1024)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2590018 ,  0.29891643, -0.10697073, ...,  0.10171058,\n",
       "        0.8235103 , -0.07563843], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][5]  ##Bank in text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.731495  ,  0.23777029, -0.11657586, ...,  0.09174436,\n",
       "        1.0873696 ,  0.13204172], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[1][9]  ##Bank in text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. Embedding Shape:  Ouput shape : [batch_size, max_length, dimension]\n",
    "\n",
    "The output embeddings is of shape (2, 30, 1024), as there are 2 sentences with max length of 30 words and for each word 1D vector of length 1024 is generated. It internally tokenizes it based of spaces. If a string with less than 6 words would have been supplied, it would have appended spaces to it internally.\n",
    "\n",
    "\n",
    "\n",
    "2. bank embedding in text1 :\n",
    "array([-0.2590018 ,  0.29891643, -0.10697073, ...,  0.10171058,\n",
    "        0.8235103 , -0.07563843], dtype=float32)\n",
    "3.  bank embedding in text2 :\n",
    "array([-0.731495  ,  0.23777029, -0.11657586, ...,  0.09174436,\n",
    "        1.0873696 ,  0.13204172], dtype=float32)\n",
    "Both have different embedding according to the context of sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
