{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the text\n",
    "fn=open(\"test.txt\",\"rb\")\n",
    "lines=[]\n",
    "for line in fn:\n",
    "    line=line.strip().lower()\n",
    "    line=line.decode(\"ascii\",\"ignore\")\n",
    "    if len(line)==0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "fn.close()\n",
    "text=\"\".join(lines)\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{')': 0, ' ': 1, 'f': 2, 'g': 3, 'm': 4, 'h': 5, 'o': 6, '?': 7, 'd': 8, 's': 9, 'p': 10, 'b': 11, '7': 12, 'v': 13, ',': 14, 'w': 15, 'y': 16, '(': 17, 'r': 18, 'z': 19, 'k': 20, 'q': 21, '5': 22, 'x': 23, 'l': 24, 'a': 25, 'u': 26, 'n': 27, '6': 28, '0': 29, '-': 30, '1': 31, 't': 32, ';': 33, 'e': 34, 'i': 35, 'c': 36, '.': 37}\n",
      "****************************************************************************************************\n",
      "{0: ')', 1: ' ', 2: 'f', 3: 'g', 4: 'm', 5: 'h', 6: 'o', 7: '?', 8: 'd', 9: 's', 10: 'p', 11: 'b', 12: '7', 13: 'v', 14: ',', 15: 'w', 16: 'y', 17: '(', 18: 'r', 19: 'z', 20: 'k', 21: 'q', 22: '5', 23: 'x', 24: 'l', 25: 'a', 26: 'u', 27: 'n', 28: '6', 29: '0', 30: '-', 31: '1', 32: 't', 33: ';', 34: 'e', 35: 'i', 36: 'c', 37: '.'}\n"
     ]
    }
   ],
   "source": [
    "#Indexing\n",
    "chars=set([c for c in text])\n",
    "n_chars=len(chars)\n",
    "c_to_i=dict((c,i) for i,c in enumerate(chars))\n",
    "i_to_c=dict((i,c) for i,c in enumerate(chars))\n",
    "# print(c_to_i)\n",
    "# print(\"*\"*100)\n",
    "# print(i_to_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=10\n",
    "step=1\n",
    "ip_char=[]\n",
    "label_char=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,len(text)-seq_len,step):\n",
    "    ip_char.append(text[i:i+seq_len])\n",
    "    label_char.append(text[i+seq_len])\n",
    "# print(ip_char)\n",
    "# print(label_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Datset\n",
    "X=np.zeros((len(ip_char),seq_len,n_chars),dtype=np.bool)\n",
    "y=np.zeros((len(ip_char),n_chars),dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,char in enumerate(ip_char):\n",
    "    for j,ch in enumerate(char):\n",
    "        X[i,j ,c_to_i[ch]]=1\n",
    "    y[i,c_to_i[label_char[i]]]=1\n",
    "\n",
    "\n",
    "# print(X)\n",
    "# print(\"*\"*100)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=128\n",
    "batch_size=128\n",
    "num_epoc_pr_itr=1\n",
    "num_pred_per_epoc=100\n",
    "num_itr=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Building\n",
    "model=Sequential()\n",
    "model.add(SimpleRNN(hidden_size,return_sequences=False,input_shape=(seq_len,n_chars),unroll=True))\n",
    "model.add(Dense(n_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Iteration -------------------- 0\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 102us/step - loss: 0.0858\n",
      "Generating --------------put layer \n",
      "put layer collects input patterns. the outputs. this describes feature extraction, which accomplishes a utilit****************************************************************************************************\n",
      "Iteration -------------------- 1\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 101us/step - loss: 0.0848\n",
      "Generating --------------sk modelin\n",
      "sk modeling and constructing proprietary indicators about a security; potential outputs could be buy, hold or ****************************************************************************************************\n",
      "Iteration -------------------- 2\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 1s 99us/step - loss: 0.0846\n",
      "Generating --------------ators and \n",
      "ators and price derivatives.a neural networks are arserien ural se wheudetals iis and iaps ter instics ofpeeur****************************************************************************************************\n",
      "Iteration -------------------- 3\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 1s 99us/step - loss: 0.0840\n",
      "Generating -------------- making tr\n",
      " making trade decisions based on the data analysis.atneutor nevalod thd ta anmarss fes catin ttor menendzve op****************************************************************************************************\n",
      "Iteration -------------------- 4\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 114us/step - loss: 0.0834\n",
      "Generating -------------- risk asse\n",
      " risk assessment.a neural networks refer to systems of neurons, either organic or artificial intelligence, is ****************************************************************************************************\n",
      "Iteration -------------------- 5\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 119us/step - loss: 0.0836\n",
      "Generating --------------orecasting\n",
      "orecasting and marketing research solutions, fraud detection and risk assessment.use of neural networks raneid****************************************************************************************************\n",
      "Iteration -------------------- 6\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 116us/step - loss: 0.0807\n",
      "Generating --------------, either o\n",
      ", either organic or artificial intelligence, is swiftly gaining popularity in the development of such process ****************************************************************************************************\n",
      "Iteration -------------------- 7\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 112us/step - loss: 0.0821\n",
      "Generating --------------0 percent \n",
      "0 percent of the time while others are accurate in 70 percent of the time while others are accurate in 70 perc****************************************************************************************************\n",
      "Iteration -------------------- 8\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 115us/step - loss: 0.0823\n",
      "Generating --------------s cannot. \n",
      "s cannot. according to a specific architecture. the network bears a strong resemblance to statistical techniqu****************************************************************************************************\n",
      "Iteration -------------------- 9\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 119us/step - loss: 0.0792\n",
      "Generating -------------- it is not\n",
      " it is not so much the algorithms that endeavors to recognize relationships in a set of data through a process****************************************************************************************************\n",
      "Iteration -------------------- 10\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 121us/step - loss: 0.0791\n",
      "Generating --------------ess as tim\n",
      "ess as time-series forecasting, algorithms that endeavors to recognize relationships in a set of data through ****************************************************************************************************\n",
      "Iteration -------------------- 11\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 116us/step - loss: 0.0774\n",
      "Generating --------------er to syst\n",
      "er to systems of neurons, either organic or artificial in nature. neural networks for stocks differs. some mod****************************************************************************************************\n",
      "Iteration -------------------- 12\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 115us/step - loss: 0.0764\n",
      "Generating --------------according \n",
      "according to a specific architecture. the network grate te reches ancutpetselinerne.rae ury iched oades on the****************************************************************************************************\n",
      "Iteration -------------------- 13\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 117us/step - loss: 0.0761\n",
      "Generating --------------ural netwo\n",
      "ural networks are a series of algorithms that endeavors to recognize relationships in a set of data through a ****************************************************************************************************\n",
      "Iteration -------------------- 14\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 116us/step - loss: 0.0787\n",
      "Generating --------------thematical\n",
      "thematical function that may be nonlinear interdependencies and patterns may comprise a list of quantities for****************************************************************************************************\n",
      "Iteration -------------------- 15\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 116us/step - loss: 0.0762\n",
      "Generating --------------s. some mo\n",
      "s. some models predict the correct stock prices 50 to 60 percent improvement in efficiency is all an investor ****************************************************************************************************\n",
      "Iteration -------------------- 16\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 123us/step - loss: 0.0740\n",
      "Generating -------------- vast amou\n",
      " vast amounts of data.they are used in a variety of applications for financial operations of a human brain to ****************************************************************************************************\n",
      "Iteration -------------------- 17\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 124us/step - loss: 0.0757\n",
      "Generating --------------k?a neural\n",
      "k?a neural networks in making price prediction varies.applications for financial services, from forecasting an****************************************************************************************************\n",
      "Iteration -------------------- 18\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 117us/step - loss: 0.0758\n",
      "Generating --------------antities f\n",
      "antities for technical analysis cannot. according to redesign the output criteria. the concept of neural netwo****************************************************************************************************\n",
      "Iteration -------------------- 19\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 120us/step - loss: 0.0728\n",
      "Generating --------------on feeds t\n",
      "on feeds the signal produced by a multiple linear regression into an activation function that may be nonlinear****************************************************************************************************\n",
      "Iteration -------------------- 20\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 122us/step - loss: 0.0734\n",
      "Generating --------------raction, w\n",
      "raction, which pcedict of petrens,efis al peisklystin mathis  ofercont remard teod tho smha aed ofict or the t****************************************************************************************************\n",
      "Iteration -------------------- 21\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 121us/step - loss: 0.0738\n",
      "Generating --------------ial output\n",
      "ial outputs could be buy, hold or sell.hidden layers fine-tune the input weightings until the neural networks ****************************************************************************************************\n",
      "Iteration -------------------- 22\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14988/14988 [==============================] - 2s 115us/step - loss: 0.0732\n",
      "Generating --------------thmic trad\n",
      "thmic trading, business applications for stocks differs. some models predict the correct stock prices 50 to 60****************************************************************************************************\n",
      "Iteration -------------------- 23\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 114us/step - loss: 0.0755\n",
      "Generating -------------- network i\n",
      " network is a mathematical function that may be nonlinear.in a multi-layered perceptron feeds the signal produ****************************************************************************************************\n",
      "Iteration -------------------- 24\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 117us/step - loss: 0.0734\n",
      "Generating -------------- is a seri\n",
      " is a series of algorithmic trading, securities classification, credit risk modeling and constructing propriet****************************************************************************************************\n",
      "Iteration -------------------- 25\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 119us/step - loss: 0.0717\n",
      "Generating --------------st in the \n",
      "st in the development of trading systems.basics of neural networks in making price predictive power regarding ****************************************************************************************************\n",
      "Iteration -------------------- 26\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 120us/step - loss: 0.0718\n",
      "Generating --------------ng systems\n",
      "ng systems.basics of neural networks refer to systems of neurons, either orgtiic si ia tho toon aug inturn.tye****************************************************************************************************\n",
      "Iteration -------------------- 27\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 117us/step - loss: 0.0715\n",
      "Generating --------------lects inpu\n",
      "lects input patterns. the outputs. this describes feature extraction, which accomplishes a utility similar to ****************************************************************************************************\n",
      "Iteration -------------------- 28\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 114us/step - loss: 0.0710\n",
      "Generating --------------ctive powe\n",
      "ctive power regarding the output layer has classification, credit risk modeling and constructing proprietary i****************************************************************************************************\n",
      "Iteration -------------------- 29\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 120us/step - loss: 0.0704\n",
      "Generating --------------s not so m\n",
      "s not so much the algorithm that matters; it is the well-prepared input data on the targeted indicator that ul****************************************************************************************************\n",
      "Iteration -------------------- 30\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 121us/step - loss: 0.0702\n",
      "Generating --------------research s\n",
      "research solutions, fraud detection and risk assessment.use of neural networks are broadly used, with applicat****************************************************************************************************\n",
      "Iteration -------------------- 31\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 120us/step - loss: 0.0708\n",
      "Generating --------------dicators a\n",
      "dicators about a security; poteutial hathens iog andatidactoritha nelranongeresrornss fe aucht on ireding in d****************************************************************************************************\n",
      "Iteration -------------------- 32\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 130us/step - loss: 0.0732\n",
      "Generating --------------istical me\n",
      "istical methods such as principal component analysis. the networks are a series of algorithms that endeavors t****************************************************************************************************\n",
      "Iteration -------------------- 33\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 124us/step - loss: 0.0684\n",
      "Generating --------------inear.in a\n",
      "inear.in a multi-layered perceptron and is similar to a multiple linear regression analysis.a neural networks ****************************************************************************************************\n",
      "Iteration -------------------- 34\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 111us/step - loss: 0.0725\n",
      "Generating --------------f neural n\n",
      "f neural networks can distinguish subtle nonlinear.in a multi-layered perceptron and is similar to a multiple ****************************************************************************************************\n",
      "Iteration -------------------- 35\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 118us/step - loss: 0.0703\n",
      "Generating --------------eural netw\n",
      "eural networks can distinguish subtle nonlinear interdependencies and patterns may map. for instance, the patt****************************************************************************************************\n",
      "Iteration -------------------- 36\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 119us/step - loss: 0.0702\n",
      "Generating -------------- networks \n",
      " networks for stocks differs. some models predict the correct stock prices 50 to 60 percent of the time while ****************************************************************************************************\n",
      "Iteration -------------------- 37\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 115us/step - loss: 0.0681\n",
      "Generating --------------regarding \n",
      "regarding the output layer has classification, cr diturs anshasses fesetfoa  nelrypo anautar nofun the he pept****************************************************************************************************\n",
      "Iteration -------------------- 38\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 110us/step - loss: 0.0702\n",
      "Generating --------------bes featur\n",
      "bes feature extraction, which accomplishes a utility similar to a multiple linear regressiof anal secsule. the****************************************************************************************************\n",
      "Iteration -------------------- 39\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 113us/step - loss: 0.0691\n",
      "Generating --------------ss as time\n",
      "ss as time-series forecasting and marketing research to fraud detection and risk assessment.a neural networks ****************************************************************************************************\n",
      "Iteration -------------------- 40\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 114us/step - loss: 0.0677\n",
      "Generating --------------odels pred\n",
      "odels predict the correct stock prices 50 to 60 percent of the time while others are accurate in 70 percent of****************************************************************************************************\n",
      "Iteration -------------------- 41\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 118us/step - loss: 0.0689\n",
      "Generating --------------minimal. i\n",
      "minimal. it is hypothesized that hidden layers extrapolate salient features in the input data on the targeted ****************************************************************************************************\n",
      "Iteration -------------------- 42\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 113us/step - loss: 0.0681\n",
      "Generating --------------twork. a n\n",
      "twork. a neuron in a neural networks for stock market price predictions for financial services, from forecasti****************************************************************************************************\n",
      "Iteration -------------------- 43\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 117us/step - loss: 0.0676\n",
      "Generating --------------or that ul\n",
      "or that ultimately determines the level of success of a neural networks margin of error is minimal. it is hypo****************************************************************************************************\n",
      "Iteration -------------------- 44\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 123us/step - loss: 0.0677\n",
      "Generating -------------- which inp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " which input patterns may map. for instance, the patterns may map. for instance, the patterns may map. for ins****************************************************************************************************\n",
      "Iteration -------------------- 45\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 122us/step - loss: 0.0666\n",
      "Generating -------------- neural ne\n",
      " neural networks can adapt to changing input; so the network bears a strong resemblance to statistical methods****************************************************************************************************\n",
      "Iteration -------------------- 46\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 120us/step - loss: 0.0690\n",
      "Generating --------------e broadly \n",
      "e broadly used, with applications in financial operations, enterprise planning, trading, securities classifica****************************************************************************************************\n",
      "Iteration -------------------- 47\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 127us/step - loss: 0.0685\n",
      "Generating -------------- all an in\n",
      " all an investor can ask for from a neural networksneural networksneural networksneural networksneural network****************************************************************************************************\n",
      "Iteration -------------------- 48\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 119us/step - loss: 0.0693\n",
      "Generating --------------nt of such\n",
      "nt of such process as time-series forecasting and marketing research to fraud detection and risk assessment.a ****************************************************************************************************\n",
      "Iteration -------------------- 49\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 119us/step - loss: 0.0663\n",
      "Generating --------------ons, enter\n",
      "ons, enterrrise sl ins alyetinns chathendittin ithe sedaat bnoulanng nee ary noreditarei neudalansy ineurad in****************************************************************************************************\n",
      "Iteration -------------------- 50\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 122us/step - loss: 0.0673\n",
      "Generating --------------nected nod\n",
      "nected nodes. each node is a perceptrons are arranged in interconnected layers. the input weightings until the****************************************************************************************************\n",
      "Iteration -------------------- 51\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 114us/step - loss: 0.0672\n",
      "Generating --------------l in natur\n",
      "l in nature. neural networks, in the world of finance, assist in the development of such process as time-serie****************************************************************************************************\n",
      "Iteration -------------------- 52\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 112us/step - loss: 0.0647\n",
      "Generating --------------s. some ha\n",
      "s. some have posited that a 10 percent improvement in efficiency is all an investor can ask for from a neural ****************************************************************************************************\n",
      "Iteration -------------------- 53\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 116us/step - loss: 0.0670\n",
      "Generating --------------orld of fi\n",
      "orld of finance, assist in the development of trading systems.basics of neural networks can distinguish subtle****************************************************************************************************\n",
      "Iteration -------------------- 54\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 119us/step - loss: 0.0661\n",
      "Generating --------------neural net\n",
      "neural networks are a series of algorithms that endeavors to recognize relationships between vast amounts of d****************************************************************************************************\n",
      "Iteration -------------------- 55\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 116us/step - loss: 0.0667\n",
      "Generating --------------orksneural\n",
      "orksneural networks in making price predictions for financial services, from forecasting and marketing researc****************************************************************************************************\n",
      "Iteration -------------------- 56\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 122us/step - loss: 0.0674\n",
      "Generating --------------ing to a s\n",
      "ing to a specific architecture. the networks heve alserrsims. foat eoseha aeg apdictain for aro es conprice wh****************************************************************************************************\n",
      "Iteration -------------------- 57\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 123us/step - loss: 0.0671\n",
      "Generating --------------ed on the \n",
      "ed on the data analysis. the network bears a strong resemblance to statistical methods such as forecasting and****************************************************************************************************\n",
      "Iteration -------------------- 58\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 116us/step - loss: 0.0681\n",
      "Generating --------------of all ins\n",
      "of all instances. some have posited that a 10 percent of the time while others are accurate in 70 percent of t****************************************************************************************************\n",
      "Iteration -------------------- 59\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 114us/step - loss: 0.0654\n",
      "Generating --------------are arrang\n",
      "are arranged in interconnected layers. the input data on the targeted indicators about a security; potential o****************************************************************************************************\n",
      "Iteration -------------------- 60\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 111us/step - loss: 0.0658\n",
      "Generating --------------polate sal\n",
      "polate salient features in the input data that have prediction varies.applications such as curve fitting and r****************************************************************************************************\n",
      "Iteration -------------------- 61\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 113us/step - loss: 0.0649\n",
      "Generating --------------y the huma\n",
      "y the human brain to recognize underlying relationships between vast amounts of data.they are used in a variet****************************************************************************************************\n",
      "Iteration -------------------- 62\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 115us/step - loss: 0.0657\n",
      "Generating -------------- the outpu\n",
      " the outputs. this describes feature extraction, which accomplishes a utility similar to a multiple linear reg****************************************************************************************************\n",
      "Iteration -------------------- 63\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 116us/step - loss: 0.0645\n",
      "Generating -------------- of neural\n",
      " of neural networks in making price prediction varies.applications for stocks differs. some models predict the****************************************************************************************************\n",
      "Iteration -------------------- 64\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 115us/step - loss: 0.0646\n",
      "Generating --------------lyzed by u\n",
      "lyzed by using previously developed algorithms. it is not so much the algorithms. it is not so much the algori****************************************************************************************************\n",
      "Iteration -------------------- 65\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 114us/step - loss: 0.0643\n",
      "Generating --------------subtle non\n",
      "subtle nonlinear.in a multi-layered perceptron and ind inpor onccitiss an tuma the inela ne concit orglatics a****************************************************************************************************\n",
      "Iteration -------------------- 66\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 112us/step - loss: 0.0621\n",
      "Generating --------------forecastin\n",
      "forecasting and marketing research to fraud detection and risk assessment.use of neural networks for stocks di****************************************************************************************************\n",
      "Iteration -------------------- 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 116us/step - loss: 0.0645\n",
      "Generating --------------atterns. t\n",
      "atterns. the output layer collects and classifies information according to a specific architecture. the networ****************************************************************************************************\n",
      "Iteration -------------------- 68\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 117us/step - loss: 0.0645\n",
      "Generating --------------on varies.\n",
      "on varies.applications for financial operations, enterprise planning, trading, business applications for finan****************************************************************************************************\n",
      "Iteration -------------------- 69\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 114us/step - loss: 0.0654\n",
      "Generating --------------ary indica\n",
      "ary indicators and price derivatives.a neural networks can distinguish subtle nonlinear interdependencies and ****************************************************************************************************\n",
      "Iteration -------------------- 70\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 112us/step - loss: 0.0635\n",
      "Generating --------------ssificatio\n",
      "ssification, credit risk modeling and constructing proprietary indicators about a security; potential outputs ****************************************************************************************************\n",
      "Iteration -------------------- 71\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 112us/step - loss: 0.0642\n",
      "Generating --------------cording to\n",
      "cording to research, the accuracy if n ural netwinks ane busa thed ct ommprtict inpliseterenod ve ofpreceinat ****************************************************************************************************\n",
      "Iteration -------------------- 72\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 114us/step - loss: 0.0634\n",
      "Generating --------------rate in 70\n",
      "rate in 70 percent of the time while others are accurate in 70 percent of the time while others are accurate i****************************************************************************************************\n",
      "Iteration -------------------- 73\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 114us/step - loss: 0.0638\n",
      "Generating --------------multi-laye\n",
      "multi-layered perceptron feeds the signal produced by a multiple linear regression into an activation function****************************************************************************************************\n",
      "Iteration -------------------- 74\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 114us/step - loss: 0.0631\n",
      "Generating --------------others are\n",
      "others are accurate in 70 percent of the time while others are accurate in 70 percent of the time while others****************************************************************************************************\n",
      "Iteration -------------------- 75\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 115us/step - loss: 0.0649\n",
      "Generating --------------nships bet\n",
      "nships between vast amounts of data.they are used in a variety of applications such as curve fitting and regre****************************************************************************************************\n",
      "Iteration -------------------- 76\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 114us/step - loss: 0.0633\n",
      "Generating --------------s in the i\n",
      "s in the input layer has classifications or funa tha  nporine ray in urneural nerworks ar eadendity in th inea****************************************************************************************************\n",
      "Iteration -------------------- 77\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 111us/step - loss: 0.0637\n",
      "Generating --------------res in the\n",
      "res in the input weightings until the neural networks can adapt to changing input; so the network bears a stro****************************************************************************************************\n",
      "Iteration -------------------- 78\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 113us/step - loss: 0.0647\n",
      "Generating --------------onnected l\n",
      "onnected layers. the input weightings until the neural networks can adapt to changing input; so the network ge****************************************************************************************************\n",
      "Iteration -------------------- 79\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 114us/step - loss: 0.0655\n",
      "Generating --------------ceptron (m\n",
      "ceptron (mlp), perceptron and is similar to statistical methods such as principal component analysis. the netw****************************************************************************************************\n",
      "Iteration -------------------- 80\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 117us/step - loss: 0.0637\n",
      "Generating --------------t hidden l\n",
      "t hidden layers fine-tune the input weightings until the neural networks refer to systems of neurons, either o****************************************************************************************************\n",
      "Iteration -------------------- 81\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 123us/step - loss: 0.0673\n",
      "Generating --------------widespread\n",
      "widespread adoption in business analytics and product maintenance. neural networks can distinguish subtle nonl****************************************************************************************************\n",
      "Iteration -------------------- 82\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 122us/step - loss: 0.0634\n",
      "Generating --------------alysis. th\n",
      "alysis. the network generates the best possible result without needing to research, the accuracy of neural net****************************************************************************************************\n",
      "Iteration -------------------- 83\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 127us/step - loss: 0.0651\n",
      "Generating --------------a that hav\n",
      "a that have predictions for financial services, from forecasting and marketing research solutions, fraud detec****************************************************************************************************\n",
      "Iteration -------------------- 84\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 122us/step - loss: 0.0619\n",
      "Generating --------------fraud dete\n",
      "fraud detection and risk assessment.a neural network evaluates price data and unearths opportunities for makin****************************************************************************************************\n",
      "Iteration -------------------- 85\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 122us/step - loss: 0.0643\n",
      "Generating --------------aining pop\n",
      "aining popularity in the development of such process as time-series forecasting and marketing research to frau****************************************************************************************************\n",
      "Iteration -------------------- 86\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 123us/step - loss: 0.0638\n",
      "Generating --------------d nodes. e\n",
      "d nodes. each node is a perceptron feeds the signal produced by a multiple linear regression analysis. the net****************************************************************************************************\n",
      "Iteration -------------------- 87\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 120us/step - loss: 0.0658\n",
      "Generating --------------l.hidden l\n",
      "l.hidden layers fine-tune the input weightings until the neural network evaluates price data and unearths oppo****************************************************************************************************\n",
      "Iteration -------------------- 88\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 118us/step - loss: 0.0629\n",
      "Generating --------------ent featur\n",
      "ent features in the input weightings until the neural networks are a series of algorithms that mimic the opera****************************************************************************************************\n",
      "Iteration -------------------- 89\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 117us/step - loss: 0.0640\n",
      "Generating --------------ural netwo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ural networks, which has its roots in artificial in nature. neural networks, which has its roots in artificial****************************************************************************************************\n",
      "Iteration -------------------- 90\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 117us/step - loss: 0.0641\n",
      "Generating --------------s of a neu\n",
      "s of a neural networks are a series of algorithms that endeavors to recognize relationships in a set of data t****************************************************************************************************\n",
      "Iteration -------------------- 91\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 119us/step - loss: 0.0633\n",
      "Generating --------------es. each n\n",
      "es. each node is a perceptron and is similar to a multiple linear regression into an activation function that ****************************************************************************************************\n",
      "Iteration -------------------- 92\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 117us/step - loss: 0.0631\n",
      "Generating --------------le linear \n",
      "le linear regression. the perceptron feeds the signal produced by a multiple linear regression. the perceptron****************************************************************************************************\n",
      "Iteration -------------------- 93\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 126us/step - loss: 0.0643\n",
      "Generating --------------layer coll\n",
      "layer collects input patterns. the output layer has classifications or output signals to which input patterns.****************************************************************************************************\n",
      "Iteration -------------------- 94\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 118us/step - loss: 0.0633\n",
      "Generating --------------etween vas\n",
      "etween vast amounts of data.they are used in a variety of applications for financial operations of a human bra****************************************************************************************************\n",
      "Iteration -------------------- 95\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 125us/step - loss: 0.0629\n",
      "Generating --------------s for stoc\n",
      "s for stock market price predictions for financial operations of a human brain to recognize relationships betw****************************************************************************************************\n",
      "Iteration -------------------- 96\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 134us/step - loss: 0.0622\n",
      "Generating -------------- or artifi\n",
      " or artificial intelligence, is swiftly gaining popularity in the development of such process as time-series f****************************************************************************************************\n",
      "Iteration -------------------- 97\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 131us/step - loss: 0.0631\n",
      "Generating -------------- credit ri\n",
      " credit risk modeling and constructing proprietary indicator that ultimately determines the level of success o****************************************************************************************************\n",
      "Iteration -------------------- 98\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 132us/step - loss: 0.0618\n",
      "Generating --------------set of dat\n",
      "set of data through a process that mimic the operations, enterprise planning, trading, securities classificati****************************************************************************************************\n",
      "Iteration -------------------- 99\n",
      "Epoch 1/1\n",
      "14988/14988 [==============================] - 2s 134us/step - loss: 0.0623\n",
      "Generating -------------- a utility\n",
      " a utility similar to statistical techniques such as forecasting and marketing research to fraud detection and\n"
     ]
    }
   ],
   "source": [
    "#Fit and Test Data\n",
    "for itr in range(num_itr):\n",
    "    print(\"*\"*100)\n",
    "    print(\"Iteration -------------------- %d\"%(itr))\n",
    "    model.fit(X,y,batch_size,epochs=num_epoc_pr_itr)\n",
    "    \n",
    "    test_idx=np.random.randint(len(ip_char))\n",
    "    test_char=ip_char[test_idx]\n",
    "    print(\"Generating --------------%s\"%(test_char))\n",
    "    print(test_char,end=\"\")\n",
    "    for i in range(num_pred_per_epoc):\n",
    "        Xtest=np.zeros((1,seq_len,n_chars))\n",
    "        for i,ch in enumerate(test_char):\n",
    "            Xtest[0,i ,c_to_i[ch]]=1\n",
    "        pred=model.predict(Xtest,verbose=0)[0]\n",
    "        ypred=i_to_c[np.argmax(pred)]\n",
    "        print(ypred,end=\"\")\n",
    "        test_char=test_char[1:]+ypred\n",
    "        \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
